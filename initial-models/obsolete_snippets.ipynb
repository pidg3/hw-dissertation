{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-isolation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Snippets that may be useful for report writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_numerical(value, column_data, numeric_displacement=0.1):\n",
    "    \n",
    "    # We use this to ensure zero values are perturbed\n",
    "    ADDITIONAL_VALUE = 0.0001\n",
    "    \n",
    "    # Decide whether to increase or decrease\n",
    "    direction = random.randrange(2)\n",
    "    \n",
    "    # If increasing - round up\n",
    "    if (direction == 0):\n",
    "        new_value = value * (1 + numeric_displacement) + ADDITIONAL_VALUE\n",
    "        new_value = math.ceil(new_value)\n",
    "        \n",
    "    # If decreasing - round down\n",
    "    else:\n",
    "        new_value = value * (1 - numeric_displacement) - ADDITIONAL_VALUE\n",
    "        new_value = math.floor(new_value)\n",
    "    \n",
    "    # Check no higher/lower than max/min values\n",
    "    if ('max' in column_data):\n",
    "        new_value = min(new_value, column_data['max'])\n",
    "    if ('min' in column_data):\n",
    "        new_value = max(new_value, column_data['min'])\n",
    "\n",
    "    return new_value\n",
    "\n",
    "\n",
    "def perturb_ordinal(value, column_data):\n",
    "    \n",
    "    # Get total number of values\n",
    "    num_values = len(column_data['values'])\n",
    "    \n",
    "    # Work out index of value\n",
    "    value_index = 0\n",
    "    for idx, val in enumerate(column_data['values']):\n",
    "        if val == value:\n",
    "            value_index = idx\n",
    "            break\n",
    "        \n",
    "    # Decide whether to increase or decrease\n",
    "    movement = 1 if random.random() < 0.5 else -1\n",
    "    \n",
    "    # Return value, looping to other end if required\n",
    "    if value_index + movement < 0:\n",
    "        return column_data['values'][num_values - 1]\n",
    "    \n",
    "    elif value_index + movement >= num_values:\n",
    "        return column_data['values'][0]\n",
    "    \n",
    "    else:\n",
    "        return column_data['values'][value_index + movement]\n",
    "    \n",
    "def perturb_nominal(value, column_data):\n",
    "    \n",
    "    # Remove actual value from the list of values\n",
    "    other_values = list(filter((lambda v: v != value), column_data['values']))\n",
    "    \n",
    "    # Randomly select a new value from this new list, return\n",
    "    return random.choice(other_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More sophisticated implementation of sensitivity\n",
    "\n",
    "# TODO: could PSO be used for this to get to the global maximum? \n",
    "\n",
    "def calculate_sensitivity(metadata_local, df_local, numeric_displacement=0.1, proportion_features_perturbed=0.1, perturbation_epochs=10):\n",
    "        \n",
    "    # Filter our features not used\n",
    "    used_features = list(filter((lambda feat: feat['type'] != 'outcome' and feat['used'] == True), metadata_local))\n",
    "    \n",
    "    # Keep track of the maximum explanation difference\n",
    "    max_difference = 0\n",
    "                \n",
    "    # Calculate how many features to perturb\n",
    "    n = math.ceil(len(used_features) * proportion_features_perturbed)\n",
    "    \n",
    "    # Loop through each perturbation epoch\n",
    "    for p_epoch in range(perturbation_epochs):\n",
    "                \n",
    "        # Randomly decide which features to peturb\n",
    "        features_to_perturb = random.sample(used_features, n)\n",
    "        \n",
    "        # Make a copy of the instance\n",
    "        instance_copy = df_local.iloc[index_to_explain,:].copy(deep=True)\n",
    "        \n",
    "        # Apply the perturbations, varying the technique depending on the data type\n",
    "        for column in features_to_perturb:\n",
    "                        \n",
    "            if column['type'] == 'numerical':\n",
    "                instance_copy[column['index']] = perturb_numerical(instance_copy[column['index']], column)\n",
    "            \n",
    "            elif column['type'] == 'ordinal':\n",
    "                instance_copy[column['index']] = perturb_ordinal(instance_copy[column['index']], column)\n",
    "                \n",
    "            elif column['type'] == 'nominal':\n",
    "                instance_copy[column['index']] = perturb_nominal(instance_copy[column['index']], column)\n",
    "            \n",
    "            else:\n",
    "                print('Error - not a recognised type')\n",
    "        \n",
    "        # Generate an explantion\n",
    "        perturbed_shap_values = explainer.shap_values(instance_copy, nsamples=num_perturbations)\n",
    "        \n",
    "        # Calculate L2 distance between this and the original explanation\n",
    "        difference = np.linalg.norm(np.array(perturbed_shap_values) - np.array(shap_values))\n",
    "\n",
    "        if difference > max_difference:\n",
    "            max_difference = difference\n",
    "\n",
    "    return max_difference\n",
    "\n",
    "results = []\n",
    "\n",
    "for epochs in range(30):\n",
    "    print(f'Starting with {epochs} epochs')\n",
    "    sensitivity = calculate_sensitivity(metadata, dataframe, perturbation_epochs=epochs)\n",
    "    results.append({\n",
    "        'epochs': epochs,\n",
    "        'sensitivity': sensitivity\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other metrics for model training\n",
    "\n",
    "#       tf.keras.metrics.Truenegatives(name='tp'),\n",
    "#       tf.keras.metrics.Falsenegatives(name='fp'),\n",
    "#       tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "#       tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "#       tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-management",
   "metadata": {},
   "source": [
    "### Notes on the fidelity metric\n",
    "\n",
    "It is a bit confusing. \n",
    "\n",
    "The first part is (perturbation) dot (explanation). The metric is made higher by these - in other words, an explanation that is more confident in a particular feature being important, and/or a large perturbation to that feature, should result in a larger change to the model output. This seems reasonable. \n",
    "\n",
    "The second part of the actual change in the model output, squared.\n",
    "\n",
    "The end result is the first part minus the second part. \n",
    "\n",
    "A large negative value implies high FIdidelity (i.e. changing the inputs in line with the explanation has, indeed, resulted in a large change to model output) - this is presumably why Yeh. et al added the [in] to the name of the metric.\n",
    "\n",
    "NB I'd previously written this TODO: *think about what happends if we are already at the mid-point for the variables we are perturbing? Do we need different approaches?*. We don't need different approaches, instead we rely on the first part of the formula, small perturbations = smaller expected change in the model output. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
